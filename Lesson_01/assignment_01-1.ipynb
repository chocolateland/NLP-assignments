{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在大师的眼中，语言表达可能是这样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = \"\"\"\n",
    "master = 人 意 动 名 结尾\n",
    "人 = 你 | 我 | 他 | 你们 | 我们 | 他们\n",
    "意 = 想 | 欲 | 思 \n",
    "动 = 读 | 打 | 练 | 跑 | 练习\n",
    "名 = 书 | 功夫 | 文笔 | 剑 \n",
    "结尾= ！ | ？\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在平凡人眼中，可以通俗的表示为：\n",
    "person = \"\"\"\n",
    "person = 谁 想 干 什么 结尾\n",
    "谁 = 我 | 洒家 | 侬 | 啷个\n",
    "想 = 想要 | 准备\n",
    "干 = 走 | 跑 | 做\n",
    "什么 = 去哪 | 啥事 | 啥子\n",
    "结尾 = ？ | 。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "choice = random.choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grammar(grammar_str, split= '=', line_split = '\\n'):\n",
    "    grammar = {}\n",
    "    for line in grammar_str.split(line_split):\n",
    "        if not line.strip():continue\n",
    "        exp, stmt = line.split(split)\n",
    "        grammar[exp.strip()] = [s.split() for s in stmt.split('|')]\n",
    "    return grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(gram, target):\n",
    "    if target not in gram: return target   # means target is a terminal expression\n",
    "    \n",
    "    expand = [generate(gram, t) for t in choice(gram[target])]   #迭代？\n",
    "    return ''.join([e if e != '/n' else '\\n' for e in expand if e != 'null'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(gram, target, n):\n",
    "    for i in range(n):\n",
    "        print(generate(gram, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_gammar = create_grammar(master, split= '=', line_split = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'master': [['人', '意', '动', '名', '结尾']],\n",
       " '人': [['你'], ['我'], ['他'], ['你们'], ['我们'], ['他们']],\n",
       " '意': [['想'], ['欲'], ['思']],\n",
       " '动': [['读'], ['打'], ['练'], ['跑'], ['练习']],\n",
       " '名': [['书'], ['功夫'], ['文笔'], ['剑']],\n",
       " '结尾': [['！'], ['？']]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_gammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'他思读剑！'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(gram = master_gammar, target = 'master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "他们思练习剑！\n",
      "他想打功夫！\n",
      "你们欲跑书？\n"
     ]
    }
   ],
   "source": [
    "generate_n(gram = master_gammar, target = 'master', n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_gammar = create_grammar(person, split= '=', line_split = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'person': [['谁', '想', '干', '什么', '结尾']],\n",
       " '谁': [['我'], ['洒家'], ['侬'], ['啷个']],\n",
       " '想': [['想要'], ['准备']],\n",
       " '干': [['走'], ['跑'], ['做']],\n",
       " '什么': [['去哪'], ['啥事'], ['啥子']],\n",
       " '结尾': [['？'], ['。']]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_gammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我准备跑去哪。'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(gram = person_gammar, target = 'person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我准备做去哪。\n",
      "侬想要走啥子？\n",
      "啷个准备跑啥子？\n",
      "侬想要跑啥事？\n",
      "侬准备做啥事？\n",
      "啷个准备做啥子？\n",
      "侬准备跑啥子。\n",
      "侬准备走啥事。\n",
      "啷个想要做啥事？\n",
      "侬想要走去哪？\n"
     ]
    }
   ],
   "source": [
    "generate_n(gram = person_gammar, target = 'person', n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(string): return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 驱动器 C 中的卷是 系统\n",
      " 卷的序列号是 843A-F5DF\n",
      "\n",
      " C:\\Users\\Lee\\Downloads\\Homeworks\\Lesson-01\\assignment01 的目录\n",
      "\n",
      "2019/08/29  06:58    <DIR>          .\n",
      "2019/08/29  06:58    <DIR>          ..\n",
      "2019/08/28  22:09    <DIR>          .ipynb_checkpoints\n",
      "2019/08/29  06:58             9,237 assignment_01-1.ipynb\n",
      "2019/08/29  06:56             6,656 assignment_01-2.ipynb\n",
      "2019/08/29  06:30    <DIR>          bianjing01\n",
      "2019/08/29  06:58    <DIR>          junnl\n",
      "2019/08/28  23:09             2,516 lesson-01理论部分.txt\n",
      "2019/08/29  06:13        46,833,745 movie_comments.csv\n",
      "2019/08/28  22:51        44,506,129 movie_comments.txt\n",
      "2019/07/05  22:07             1,431 NLP第四期+李兆银+qa2.txt\n",
      "2019/07/06  09:52             1,185 programme-1.py\n",
      "2019/07/06  12:31             4,301 programme-2and3.py\n",
      "2017/07/28  10:05         1,660,053 train.txt\n",
      "               9 个文件     93,025,253 字节\n",
      "               5 个目录 40,295,723,008 可用字节\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Lee\\AppData\\Local\\Temp\\jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 1.008 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "from operator import add, mul\n",
    "from collections import Counter\n",
    "import jieba\n",
    "import re\n",
    "\n",
    "TOKEN = []\n",
    "for i, line in enumerate(open('train.txt','r',encoding='gbk',errors='ignore')):\n",
    "    if i % 100 == 0: print(i)\n",
    "    if i > 50000: break    \n",
    "    line = re.sub(r'[^\\w\\s]','',line)\n",
    "    line = line.replace('\\n', '')\n",
    "    TOKEN += cut(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import re \n",
    "import numpy as np\n",
    "import jieba\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去除多余的无用字符\n",
    "def token(string):\n",
    "    #we will learn the regular expression next course.\n",
    "    return re.findall('\\w+', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取csv文件指定的列的内容，并且返回干净的内容\n",
    "def readCsv(fileName,_countName):\n",
    "    fileContent = pd.read_csv(fileName,encoding='utf-8')\n",
    "    targetContent = []\n",
    "    for i, v in enumerate (fileContent[_countName]):\n",
    "        targetContent.append(v)\n",
    "        clearContent = [''.join(token(str(b))) for b in targetContent]\n",
    "    return clearContent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取txt文件\n",
    "def readTxt(_fileName):#文件名不能当作参数传\n",
    "  data = []\n",
    "  for line in open('train.txt' ,encoding='UTF-8'): #设置文件对象并读取每一行文件\n",
    "      data.append(line)               #将每一行文件加入到list中\n",
    "  cleanData = [''.join(token(str(a)))for a in data]\n",
    "  return cleanData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writefileContentTOFile(_writeToFileName,_content):\n",
    "    with open(\"language.txt\", 'w',encoding='utf-8') as f:  #文件名不能当作参数传\n",
    "         for a in _content:\n",
    "             f.write(str(a) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('健康保险', 1349), ('什么是', 1149), ('保险是否', 958), ('我的', 726), ('残疾保险', 659), ('房主保险', 603), ('我可以', 529), ('保险吗', 511), ('是否覆盖', 504), ('家庭保险', 440)]\n"
     ]
    }
   ],
   "source": [
    "#jieba切词\n",
    "def cut(string): return list(jieba.cut(string))\n",
    "languageMode = readTxt('train.txt')   #readCsv('movie_comments.csv','comment') + readTxt('train.txt') \n",
    "writefileContentTOFile(\"language.txt\",languageMode) \n",
    "\n",
    "#获取 n-gram language model\n",
    "TOKEN = []\n",
    "#enumerate  同时列出数据和数据下标\n",
    "for i, line in enumerate((open(\"language.txt\",encoding='utf-8'))):\n",
    "    TOKEN += cut(line.strip())\n",
    "#Counter（计数器）是对字典的补充，用于追踪值的出现次数\n",
    "#words_count = Counter(_TOKEN)\n",
    "TOKEN = [str(t) for t in TOKEN]\n",
    "TOKEN_2_GRAM = [''.join(TOKEN[i:i+2]) for i in range(len(TOKEN[:-2]))]\n",
    "count = Counter(TOKEN_2_GRAM)\n",
    "print(count.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    " #1-gram language model的概率\n",
    "def prob_1(word,TOKEN):\n",
    "    words_count = Counter(TOKEN)\n",
    "    return words_count[word] / len(TOKEN)\n",
    "#2-gram language model的概率\n",
    "def prob_2(word1, word2):\n",
    "    words_count_2 = Counter(TOKEN_2_GRAM)\n",
    "    if word1 + word2 in words_count_2: return words_count_2[word1+word2] / len(TOKEN_2_GRAM)\n",
    "    else:\n",
    "        return 1 / len(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#由2-gram language model\n",
    "def get_probablity(sentence):\n",
    "    words = cut(sentence)\n",
    "    sentence_pro = 1\n",
    "    for i, word in enumerate(words[:-1]):\n",
    "        next_ = words[i + 1]\n",
    "        #probability = prob_2(word, next_)/prob_1(word) #分母可能为0\n",
    "        #if prob_1(word) == 0:#当有一项概率为0，则返回0\n",
    "        #return 0\n",
    "        probability = prob_2(word, next_)/len(TOKEN_2_GRAM) #老师课堂讲的方法\n",
    "        sentence_pro *= probability\n",
    "    return sentence_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('他思读书！', 9.665953787887186e-21), ('他欲练剑！', 9.665953787887186e-21), ('他思练习书！', 9.503138783313165e-31), ('他想读书？', 9.503138783313165e-31), ('我欲练习剑？', 9.343066262957064e-41), ('他们想打文笔？', 9.343066262957064e-41), ('我们思练习剑！', 9.343066262957064e-41), ('他们欲练习剑！', 9.343066262957064e-41), ('你想跑功夫？', 9.343066262957064e-41), ('我们思练习剑！', 9.343066262957064e-41)]\n",
      "('他思读书！', 9.665953787887186e-21)\n"
     ]
    }
   ],
   "source": [
    "def generate_best(grammar_str, typeStr):\n",
    "    dic_str = create_grammar(grammar_str, split= '=', line_split = '\\n')\n",
    "    testStrDic = []\n",
    "    for i in range(0,10):\n",
    "        strInfo = generate(gram = dic_str, target = typeStr)\n",
    "        info = (strInfo, get_probablity(strInfo))\n",
    "        testStrDic.append(info)\n",
    "    testStrDic = sorted(testStrDic, key = lambda x: x[1], reverse=True)\n",
    "    print(testStrDic)\n",
    "    return testStrDic[0]\n",
    "\n",
    "\n",
    "print(generate_best(master,'master'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
